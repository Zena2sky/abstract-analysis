{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac88699",
   "metadata": {},
   "source": [
    "\n",
    "## KCI ì‚¬íšŒê³¼í•™ ë¶„ì•¼ ì˜ì–´ì´ˆë¡ ë¶„ì„(2004â€“2024) - ê³¼ì‰ì–´íœ˜ ì‹œê°í™”ê¹Œì§€\n",
    "\n",
    "ë‘ ê°œì˜ ì—‘ì…€ íŒŒì¼(1: 2004â€“2023**, 2: 2024)ì„ ë³‘í•©í•˜ê³  ì•„ë˜ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰.\n",
    "\n",
    "**ì „ì²˜ë¦¬ ê·œì¹™:**\n",
    "- ì‚¬ìš© ì»¬ëŸ¼: `ë…¼ë¬¸ID`, `ì˜ì–´ì´ˆë¡`, `ë°œí–‰ë…„ë„`, `ì£¼ì œë¶„ì•¼` (ì˜ì–´ì œëª©ì€ ì œì™¸í•¨)\n",
    "- ì–¸ì–´ í•„í„°: ë³„ë„ ê°ì§€ ìƒëµ (ë¹„ì–´ìˆëŠ” ì´ˆë¡ë§Œ ì œê±°)\n",
    "- ê¸¸ì´ ê·œì¹™ì€ ë³„ë„ë¡œ ì ìš© ì•ˆ í•¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5749d19",
   "metadata": {},
   "source": [
    "# 1) ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e73c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df1 = pd.read_excel('KCI_SS_part1.xlsx')  # 2004â€“2023\n",
    "df2 = pd.read_excel('KCI_SS_part2.xlsx')  # 2024\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì• 3ì¤„)\n",
    "print(df1.head(3))\n",
    "print(df2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40aa797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ì»¬ëŸ¼ ì¶”ì¶œ\n",
    "df1 = df1[['ë…¼ë¬¸ID', 'ë°œí–‰ë…„ë„', 'ë…¼ë¬¸ì˜ì–´ì œëª©', 'ì˜ì–´ì´ˆë¡','ì£¼ì œë¶„ì•¼']]\n",
    "df2 = df2[['ë…¼ë¬¸ID', 'ë°œí–‰ë…„ë„', 'ë…¼ë¬¸ì˜ì–´ì œëª©', 'ì˜ì–´ì´ˆë¡','ì£¼ì œë¶„ì•¼']]\n",
    "\n",
    "#ë°ì´í„° ë³‘í•©\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "print(f\"ë³‘í•©ëœ ë°ì´í„°í”„ë ˆì„ í¬ê¸°: {df.shape}\")\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸ - ì•„ë˜ëŠ” ê²°ì¸¡ì¹˜ ì…ë‹ˆë‹¤!\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fe643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³µë°±/ë¹ˆë¬¸ìì—´ ë° ê²°ì¸¡ ë¬¸ìì—´ â†’ NA ì²˜ë¦¬\n",
    "for c in ['ë…¼ë¬¸ì˜ì–´ì œëª©', 'ì˜ì–´ì´ˆë¡']:\n",
    "    s = df[c].astype(str).str.strip().str.lower()\n",
    "    # \"nan\", \"none\", \"null\", \"<na>\", \"n/a\" ê°™ì€ ë¬¸ìì—´ ê²°ì¸¡ í† í° ì œê±°\n",
    "    s = s.replace(r'^(nan|none|null|<na>|n/a)$', '', regex=True)\n",
    "    # ë¹ˆ ë¬¸ìì—´ì„ NAë¡œ ë°”ê¾¸ê¸°\n",
    "    s = s.replace({'': pd.NA})\n",
    "    df[c] = s\n",
    "\n",
    "# ì˜ì–´ì´ˆë¡ë§Œ í•„ìˆ˜ë¡œ ë‚¨ê¸°ê¸°\n",
    "df = df.dropna(subset=['ì˜ì–´ì´ˆë¡'])\n",
    "print(f\"[OK] ì˜ì–´ì´ˆë¡ ê²°ì¸¡ ì œê±° í›„ í¬ê¸°: {df.shape}\")\n",
    "\n",
    "# ë°ì´í„° ì •ë³´ í™•ì¸\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849f470",
   "metadata": {},
   "source": [
    "### ì¶”í›„ ì£¼ì œë³„ ë¹„êµë¥¼ ìœ„í•´ 'ì£¼ì œë¶„ì•¼' ì»¬ëŸ¼ ê²°ì¸¡ ë³´ì • ë° ê³„ì¸µ ë¶„í•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ê²°ì¸¡/ìœ ì‚¬ê²°ì¸¡ ì •ì˜\n",
    "NULL_LIKE = {'', 'nan', 'none', 'null', 'na', 'ë¯¸ê¸°ì¬', 'N/A'}\n",
    "\n",
    "# ë¬¸ìì—´ í‘œì¤€í™”: ê³µë°± ì •ë¦¬, êµ¬ë¶„ì ' > 'ë¡œ í†µì¼\n",
    "s = df['ì£¼ì œë¶„ì•¼'].astype(str).str.strip()\n",
    "\n",
    "# 'ì¸ë¬¸í•™  >  ì—­ì‚¬í•™' ê°™ì€ ê²½ìš° ê³µë°± ì •ë¦¬ ë° ë‹¤ì–‘í•œ ê¸°í˜¸ í†µì¼\n",
    "s = s.replace(r'\\s*>\\s*', ' > ', regex=True)   # êµ¬ë¶„ì ì¢Œìš° ê³µë°± í†µì¼\n",
    "s = s.replace(r'\\s+', ' ', regex=True)         # ë‹¤ì¤‘ ê³µë°± â†’ ë‹¨ì¼ ê³µë°±\n",
    "\n",
    "# ìœ ì‚¬ê²°ì¸¡ì„ NAë¡œ ì¹˜í™˜\n",
    "s_lower = s.str.lower()\n",
    "s = s.where(~s_lower.isin({x.lower() for x in NULL_LIKE}), pd.NA)\n",
    "\n",
    "# ê²°ì¸¡ ì±„ì›€(ë¶„ì„ í¸ì˜ìš© ë¼ë²¨)\n",
    "s = s.fillna('ë¯¸ìƒ')\n",
    "\n",
    "# ê³„ì¸µ ë¶„í•´: ëŒ€/ì¤‘/ì†Œ ë¶„ë¥˜ (ìµœëŒ€ 3ë‹¨ê³„ë¡œ ê°€ì •í•¨, ë” ê¹Šìœ¼ë©´ ë§ˆì§€ë§‰ì— í•©ì¹¨) \n",
    "# ë‹¨ê³„ê°€ ë§ì€ ì˜ˆì‹œ : ì¸ë¬¸í•™ > í•œêµ­ì–´ì™€ë¬¸í•™ > êµ­ì–´í•™ > êµ­ì–´ì‚¬  \n",
    "parts = s.str.split(' > ', n=2, expand=True)  # n=2 â‡’ ìµœëŒ€ 3ì¡°ê°\n",
    "parts.columns = ['ëŒ€ë¶„ë¥˜','ì¤‘ë¶„ë¥˜','ì†Œë¶„ë¥˜']\n",
    "\n",
    "# ì†Œë¶„ë¥˜ì— ì—¬ì „íˆ ' > 'ê°€ ë‚¨ì•˜ë‹¤ë©´(4ë‹¨ê³„ ì´ìƒ) ë§ˆì§€ë§‰ ì¡°ê°ì— ì´ì–´ë¶™ì—¬ì§„ ìƒíƒœì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.\n",
    "\n",
    "# ì •ë¦¬ëœ ì»¬ëŸ¼ ë°˜ì˜\n",
    "df['ì£¼ì œë¶„ì•¼_í‘œì¤€'] = s\n",
    "df[['ëŒ€ë¶„ë¥˜','ì¤‘ë¶„ë¥˜','ì†Œë¶„ë¥˜']] = parts\n",
    "\n",
    "# íƒ€ì…: ë²”ì£¼í˜•ìœ¼ë¡œ ë³€í™˜(ë©”ëª¨ë¦¬ ì ˆì•½ + ê·¸ë£¹í™” ì†ë„)\n",
    "for c in ['ì£¼ì œë¶„ì•¼_í‘œì¤€','ëŒ€ë¶„ë¥˜','ì¤‘ë¶„ë¥˜','ì†Œë¶„ë¥˜']:\n",
    "    df[c] = df[c].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1526c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ë„ë³„ ë°ì´í„° ê°œìˆ˜\n",
    "print(df['ë°œí–‰ë…„ë„'].value_counts().sort_index())\n",
    "\n",
    "# ì—°ë„ë³„ ì¤‘ë¶„ë¥˜ ê°œìˆ˜\n",
    "print(df.groupby('ë°œí–‰ë…„ë„')['ì¤‘ë¶„ë¥˜'].nunique())\n",
    "\n",
    "# ì¤‘ë¶„ë¥˜ ëª©ë¡\n",
    "print(df['ì¤‘ë¶„ë¥˜'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4c112",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì €ì¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 0) ê²°ê³¼ í´ë” ìƒì„±: SS/results_SS\n",
    "out_dir = Path.cwd() / \"results_SS\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) ì €ì¥ ëŒ€ìƒ DF (df ì‚¬ìš©)\n",
    "df_to_save = df.reset_index(drop=True)\n",
    "\n",
    "# 2) íŒŒì¼ ê²½ë¡œ (íŒŒì¼ëª… ì•ì— SS ì‚¬íšŒê³¼í•™ ì ‘ë‘ì‚¬ ë¶™ì„)\n",
    "csv_path = out_dir / \"SS_eng_abstract_clean.csv\"\n",
    "pkl_path = out_dir / \"SS_eng_abstract_clean.pkl\"\n",
    "\n",
    "# 3) ì €ì¥\n",
    "df_to_save.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "df_to_save.to_pickle(pkl_path)\n",
    "\n",
    "# 4) ë¡œê·¸ & ê°„ë‹¨ ì ê²€\n",
    "print(\"[ì €ì¥ ì™„ë£Œ]\")\n",
    "print(\"Rows:\", len(df_to_save))\n",
    "print(\"CSV   â†’\", csv_path.resolve())\n",
    "print(\"Pickle â†’\", pkl_path.resolve())\n",
    "if \"ë°œí–‰ë…„ë„\" in df_to_save.columns:\n",
    "    print(\"Year range:\", int(df_to_save[\"ë°œí–‰ë…„ë„\"].min()), \"â†’\", int(df_to_save[\"ë°œí–‰ë…„ë„\"].max()))\n",
    "if \"ì˜ì–´ì´ˆë¡\" in df_to_save.columns:\n",
    "    print(\"ì˜ì–´ì´ˆë¡ NaN ê°œìˆ˜:\", int(df_to_save[\"ì˜ì–´ì´ˆë¡\"].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b969fa",
   "metadata": {},
   "source": [
    "### csv ë¯¸ë¦¬ ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72693492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = Path.cwd() / \"results_SS\" / \"SS_eng_abstract_clean.csv\"\n",
    "\n",
    "# 1) ì¡´ì¬ í™•ì¸\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f\"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_path}\")\n",
    "\n",
    "# 2) ë¡œë“œ (ì €ì¥ ì‹œ UTF-8-SIG)\n",
    "df_loaded = pd.read_csv(csv_path, encoding=\"utf-8-sig\", low_memory=False)\n",
    "\n",
    "# 3) ê°„ë‹¨ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"[ë¡œë“œ ì™„ë£Œ]\")\n",
    "print(\"shape:\", df_loaded.shape)\n",
    "print(\"columns:\", list(df_loaded.columns))\n",
    "display(df_loaded.head(5)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2e25b",
   "metadata": {},
   "source": [
    "# 2) í† í¬ë‚˜ì´ì§• ë° ë‹¨ì–´ í–‰ë ¬ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import joblib\n",
    "\n",
    "# ------------------------------\n",
    "# 0) ê²½ë¡œ (SS)\n",
    "# ------------------------------\n",
    "in_pkl  = Path(\"results_SS/SS_eng_abstract_clean.pkl\")\n",
    "out_dir = Path(\"results_SS\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ì‚°ì¶œë¬¼ ê²½ë¡œ ì •ì˜ (SSìš©)\n",
    "out_word_year_counts = out_dir / \"SS_word_year_matrix_counts.csv\"  # [í–‰=ë‹¨ì–´, ì—´=ì—°ë„] ê° ì—°ë„ì—ì„œ 'ê·¸ ë‹¨ì–´ê°€ ë“±ì¥í•œ ë¬¸ì„œ ìˆ˜' í–‰ë ¬\n",
    "out_doc_counts       = out_dir / \"SS_doc_counts.csv\"               # ì—°ë„ë³„ ì „ì²´ ë¬¸ì„œ ìˆ˜(n_docs); ë¶„ëª¨ë¡œ ì‚¬ìš©\n",
    "out_vectorizer_pkl   = out_dir / \"SS_vectorizer.pkl\"               # CountVectorizer ê°ì²´ í–¥í›„ ì¬í˜„/ì¬ì‚¬ìš©ì— í•„ìˆ˜\n",
    "out_terms_txt        = out_dir / \"SS_terms.txt\"                    # vectorizerì˜ feature_names ìˆœì„œ ê·¸ëŒ€ë¡œì˜ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸(í–‰ ì •ë ¬ í‚¤)\n",
    "out_years_npy        = out_dir / \"SS_years.npy\"                    # counts ì—´(ì—°ë„) ìˆœì„œ ë°°ì—´(2004..2024). ì—´ ì •ë ¬ í‚¤\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 1) ë°ì´í„° ë¡œë“œ (ì‹ ë¢° + ì–‡ì€ ê²€ì¦)\n",
    "# ------------------------------\n",
    "if not in_pkl.exists():\n",
    "    raise FileNotFoundError(f\"ì…ë ¥ ì—†ìŒ: {in_pkl}\")\n",
    "\n",
    "df = pd.read_pickle(in_pkl)\n",
    "df = df.rename(columns={\"ì˜ì–´ì´ˆë¡\": \"abstract_en\"})[[\"ë°œí–‰ë…„ë„\", \"abstract_en\"]]\n",
    "\n",
    "# ì–‡ì€ ê²€ì¦(ë¹ ë¥´ê³  ì•ˆì „)\n",
    "assert df[\"ë°œí–‰ë…„ë„\"].between(2004, 2024).all(), \"ì˜ˆìƒ ë°– ì—°ë„ ë°œê²¬\"\n",
    "assert df[\"abstract_en\"].notna().all(), \"ì˜ì–´ì´ˆë¡ NaN ë°œê²¬\"\n",
    "\n",
    "# ì—°ë„ ì •ë ¬ìš©\n",
    "df[\"ë°œí–‰ë…„ë„\"] = df[\"ë°œí–‰ë…„ë„\"].astype(int)\n",
    "years = np.sort(df[\"ë°œí–‰ë…„ë„\"].unique())\n",
    "print(f\"[ë¡œë“œ ì™„ë£Œ] {len(df)}ê°œ ë¬¸ì„œ, {len(years)}ê°œ ì—°ë„({years[0]}..{years[-1]})\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2) ë²¡í„°í™” (binary ì¡´ì¬ ì—¬ë¶€ ê¸°ì¤€)\n",
    "# ------------------------------\n",
    "vectorizer = CountVectorizer(\n",
    "    binary=True,\n",
    "    min_df=0.0001,\n",
    "    lowercase=True,\n",
    "    token_pattern=r\"(?u)\\b[A-Za-z][A-Za-z-]{1,}\\b\"\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"abstract_en\"])\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# ------------------------------\n",
    "# 3) ì—°ë„ë³„ counts ì§‘ê³„\n",
    "# ------------------------------\n",
    "doc_counts = df.groupby(\"ë°œí–‰ë…„ë„\").size().reindex(years, fill_value=0)\n",
    "doc_counts.to_csv(out_doc_counts, header=[\"n_docs\"])\n",
    "\n",
    "year_row_indices = {y: np.flatnonzero(df[\"ë°œí–‰ë…„ë„\"].values == y) for y in years}\n",
    "counts_mat = np.zeros((len(terms), len(years)), dtype=np.int32)\n",
    "\n",
    "for j, y in enumerate(years):\n",
    "    rows = year_row_indices[y]\n",
    "    if rows.size == 0:\n",
    "        continue\n",
    "    X_y = X[rows, :]\n",
    "    counts = (X_y > 0).sum(axis=0).A1\n",
    "    counts_mat[:, j] = counts\n",
    "\n",
    "word_year_counts = pd.DataFrame(counts_mat, index=terms, columns=years)\n",
    "word_year_counts.to_csv(out_word_year_counts, encoding=\"utf-8-sig\")\n",
    "\n",
    "# ------------------------------\n",
    "# 4) ì¬í˜„ìš© ì‚°ì¶œë¬¼ (vectorizer/terms/years) ìƒì„±\n",
    "# ------------------------------\n",
    "joblib.dump(vectorizer, out_vectorizer_pkl)\n",
    "np.save(out_years_npy, years)\n",
    "with open(out_terms_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(t + \"\\n\" for t in terms)\n",
    "\n",
    "# ------------------------------\n",
    "# 5) ë¡œê·¸\n",
    "# ------------------------------\n",
    "print(\"âœ… ì™„ë£Œ:\")\n",
    "print(\" - ì—°ë„ë³„ ë¬¸ì„œ ìˆ˜:\", out_doc_counts)\n",
    "print(\" - ë‹¨ì–´-ì—°ë„ ì¹´ìš´íŠ¸ í–‰ë ¬:\", out_word_year_counts)\n",
    "print(\" - Vectorizer:\", out_vectorizer_pkl)\n",
    "print(\" - Terms list:\", out_terms_txt)\n",
    "print(\" - Years.npy:\", out_years_npy)\n",
    "print(\" - terms ìˆ˜:\", len(terms), \"/ ë¬¸ì„œ ìˆ˜:\", X.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb1eab",
   "metadata": {},
   "source": [
    "ê²°ê³¼ : 511,787í¸ì˜ ì‚¬íšŒê³¼í•™ ì˜ì–´ ì´ˆë¡ ì¤‘ 23,314ê°œ ìœ íš¨ ë‹¨ì–´ê°€ ì¡í˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e9120",
   "metadata": {},
   "source": [
    "# 3) ì—°ë„ë³„ ë¹ˆë„ ê³„ì‚° ë° 2024ë…„ ê³¼ì‰ ì–´íœ˜ ì‹ë³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8887e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------\n",
    "# 0) ê²½ë¡œ\n",
    "# ------------------------------\n",
    "\n",
    "base_dir = Path(\"results_SS\")  \n",
    "counts_path = base_dir / \"SS_word_year_matrix_counts.csv\"\n",
    "docs_path   = base_dir / \"SS_doc_counts.csv\"\n",
    "\n",
    "out_full    = base_dir / \"SS_excess_words_2024.csv\"          # 2024ë…„ ë¶„ì„ ëŒ€ìƒ ëª¨ë“  ë‹¨ì–´ì˜ ê²°ê³¼\n",
    "out_filtered= base_dir / \"SS_excess_words_2024_filtered.csv\" # ì„ê³„ê°’ í•„í„°í•˜ì—¬ ê³¼ì‰ì–´íœ˜ë§Œ ëª¨ì€ ê²°ê³¼\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 1) ë°ì´í„° ë¡œë“œ\n",
    "# ------------------------------\n",
    "counts = pd.read_csv(counts_path, index_col=0)   # í–‰ = terms, ì—´ = years\n",
    "doc_counts = pd.read_csv(docs_path, index_col=0)[\"n_docs\"]  # ì¸ë±ìŠ¤ = years, ë°¸ë¥˜ = n_docs\n",
    "\n",
    "# ë¶„ì„ì— ì“¸ ì—°ë„ë“¤\n",
    "YEARS = [2021, 2022, 2023, 2024]\n",
    "missing = [y for y in YEARS if str(y) not in counts.columns or y not in doc_counts.index]\n",
    "if missing:\n",
    "    raise ValueError(f\"í•„ìš” ì—°ë„ ëˆ„ë½: {missing}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2) ë‹¨ì–´ì˜ ì—°ë„ë³„ ë“±ì¥ë¹„ìœ¨ p ê³„ì‚°,  p = (a+1)/(b+1) \n",
    "# ------------------------------\n",
    "p_s = {}\n",
    "for y in YEARS:\n",
    "    a = counts[str(y)].astype(float)\n",
    "    b = float(doc_counts.loc[y])\n",
    "    p_s[y] = (a + 1.0) / (b + 1.0) #aëŠ” ê·¸ ì—°ë„ì— í•´ë‹¹ ë‹¨ì–´ê°€ ë“±ì¥í•œ ë¬¸ì„œ ìˆ˜, bëŠ” ê·¸ ì—°ë„ ì „ì²´ ë¬¸ì„œ ìˆ˜\n",
    "    # ì¦‰, ê·¸ ì—°ë„ ì „ì²´ ë¬¸ì„œ ì¤‘ ëª‡ %ì—ì„œ í•´ë‹¹ ë‹¨ì–´ê°€ ì“°ì˜€ëŠ”ê°€. +1ì€ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê±¸ ë°©ì§€í•¨\n",
    "\n",
    "p_df = pd.DataFrame(p_s)  # p_dfëŠ” index = ë‹¨ì–´, columns = [2021, 2022, 2023, 2024] í˜•íƒœì˜ â€œì—°ë„ë³„ ë“±ì¥ë¹„ìœ¨ í–‰ë ¬â€\n",
    "p_df.index.name = \"term\" # ê° ë‹¨ì–´(term)ê°€ 2021â€“2024ë…„ ê° ì—°ë„ ì´ˆë¡ ì¤‘ ëª‡ %ì—ì„œ ë“±ì¥í–ˆëŠ”ê°€ë¥¼ ë‹´ì€ ë¹„ìœ¨ í–‰ë ¬\n",
    "\n",
    "# ------------------------------\n",
    "# 3) ë¶„ì„ ëŒ€ìƒ ë‹¨ì–´ ì„ íƒ (ë¹ˆë„ â‰¥ 1e-4 in 2024 AND 2023) \n",
    "# ë¹ˆë„ â‰¥ 1e-4ëŠ” í¬ê·€í•œ ì¡ìŒì„ ì œê±°í•˜ë ¤ëŠ” ëª©ì ì´ë¯€ë¡œ ë‹¨ì–´ì„ ì •ì˜ ì•ˆì •ì„±ì„ ìœ„í•´ 2023ë…„ë„ë„ í¬í•¨í•¨\n",
    "# (ì•„ë˜ì˜ ì˜ˆìƒì¹˜ ê³„ì‚°ì—ì„œëŠ” 2023ë…„ë„ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì ì´ ë‹¤ë¦„)\n",
    "# ------------------------------\n",
    "min_p = 1e-4\n",
    "mask_keep = (p_df[2024] >= min_p) & (p_df[2023] >= min_p)\n",
    "p_df = p_df.loc[mask_keep].copy()\n",
    "\n",
    "# ------------------------------\n",
    "# 4) q(2024 ì˜ˆìƒì¹˜) ê³„ì‚° - ì™¸ì‚½ ê·œì¹™\n",
    "#     q = p2022 + 2*max(p2022 - p2021, 0)   # (ì¦ê°€ ì¶”ì„¸ë©´ 2ë°° ì¦ê°€, ê°ì†Œ ì¶”ì„¸ë©´ í˜„ìƒ ìœ ì§€)\n",
    "# -> í•˜ë½í•œ ë‹¨ì–´ëŠ” ì¦ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ë³´ìˆ˜ì  ê°€ì •, ì¦‰, q >= p2022\n",
    "# -> ìƒìŠ¹í•œ ë‹¨ì–´ëŠ” ì¦ê°€ ì¶”ì„¸ë¥¼ ë°˜ì˜í•´ì„œ 2ë°° ë°˜ì˜, që¥¼ ë†’ê²Œ ì¡ì•„ Î´ = p âˆ’ qê°€ ë¶€í’€ë ¤ì§€ì§€ ì•Šë„ë¡(ë³´ìˆ˜ì  í•˜í•œ) ì„¤ê³„\n",
    "# ------------------------------\n",
    "p21 = p_df[2021].values\n",
    "p22 = p_df[2022].values\n",
    "p24 = p_df[2024].values\n",
    "\n",
    "trend = np.maximum(p22 - p21, 0.0)\n",
    "q = p22 + 2.0 * trend\n",
    "q = np.maximum(q, p22)  # ë³´ìˆ˜ì  í•˜í•œ\n",
    "\n",
    "# ------------------------------\n",
    "# 5) Î´, ratio, log10 r ê³„ì‚°\n",
    "# ------------------------------\n",
    "eps = 1e-12\n",
    "delta = p24 - q\n",
    "ratio = p24 / np.maximum(q, eps)\n",
    "log10r = np.log10(np.maximum(ratio, eps))\n",
    "\n",
    "# ------------------------------\n",
    "# 6) ê²°ê³¼ í…Œì´ë¸” êµ¬ì„±\n",
    "# ------------------------------\n",
    "out = pd.DataFrame({\n",
    "    \"p2021\": p_df[2021],\n",
    "    \"p2022\": p_df[2022],\n",
    "    \"p2023\": p_df[2023],\n",
    "    \"p2024\": p_df[2024],\n",
    "    \"q2024\": q,\n",
    "    \"delta\": delta,\n",
    "    \"ratio\": ratio,\n",
    "    \"log10_ratio\": log10r,\n",
    "})\n",
    "\n",
    "# ì •ë ¬: Î´ì™€ ratio ëª¨ë‘ í° ìˆœìœ¼ë¡œ ì°¸ê³ í•˜ê¸° ì¢‹ë„ë¡\n",
    "out_sorted = out.sort_values([\"delta\", \"ratio\"], ascending=[False, False])\n",
    "\n",
    "# ì „ì²´ ì €ì¥\n",
    "out_sorted.to_csv(out_full, encoding=\"utf-8-sig\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7) ì„ê³„ê°’ í•„í„° (ìˆ˜ì • ë²„ì „)\n",
    "#    - Î´ > 0.01  ë˜ëŠ”  log10 r > 0.1 (ê³ ì • ì»·)\n",
    "#    - + ë¹ˆë„ í•„í„°: p2024, p2023 â‰¥ 1e-4\n",
    "# ------------------------------\n",
    "gap_thr = 0.01          # ì ˆëŒ€ì  ë¹ˆë„ ì°¨ì´ ê¸°ì¤€; 0.01 = 1%p ì´ìƒì˜ ê³¼ì‰ë§Œ ì±„íƒ\n",
    "logr_thr = 0.1          #  log10(r) ê³ ì • ì»·; ë„ˆë¬´ ë§ì€ ë‹¨ì–´ê°€ í†µê³¼í•˜ì§€ ì•Šë„ë¡ ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •\n",
    "min_freq = 1e-4         # ë¶„ì„ ì—°ë„(Y)ì™€ ì§ì „ ì—°ë„(Y-1) ëª¨ë‘ p â‰¥ 1e-4ì¸ ë‹¨ì–´ë§Œ ëŒ€ìƒ\n",
    "eps = 1e-12             # ìˆ˜ì¹˜ ì•ˆì •ì„±ìš© ì•„ì£¼ ì‘ì€ ê°’(0 ë‚˜ëˆ—ì…ˆ, log(0) ë°©ì§€)\n",
    "\n",
    "# ë¹ˆë„ í•„í„° ì„ ì ìš© (Yì™€ Y-1ì—ì„œ p â‰¥ 1e-4)\n",
    "# ê·¹ì €ë¹ˆë„(í¬ê·€) ë‹¨ì–´ëŠ” ì‘ì€ ë³€ë™ì—ë„ Î´, rì´ í¬ê²Œ ì¶œë ì´ë©° log ê¸°ì¤€ì„ ì‰½ê²Œ í†µê³¼í•˜ë¯€ë¡œ\n",
    "# ë¨¼ì € ì œê±°í•´ ê³¼ê²€ì¶œì„ ì¤„ì„\n",
    "mask_freq = (out_sorted[\"p2024\"] >= min_freq) & (out_sorted[\"p2023\"] >= min_freq)\n",
    "cand = out_sorted[mask_freq]\n",
    "\n",
    "# --- ì„ê³„ì‹ ì ìš© ---\n",
    "# ì›ë…¼ë¬¸ê³¼ ë‹¤ë¥¸ ì ì€ log ê¸°ì¤€ì„ ê³ ì •ê°’(0.1)ë¡œ ë³´ìˆ˜í™”í•˜ì—¬ ê³¼ê²€ì¶œì„ ì–µì œí•¨.\n",
    "#  ì› ë…¼ë¬¸ì˜ log ì»·ì€ ëŒ€ëµ 0.075(â‰ˆ19% ì¦ê°€) ì´ë©° ì´ ë¶„ì„ì˜ ê²½ìš° 0.1(â‰ˆ26% ì¦ê°€)ë¡œ ìƒí–¥ ì¡°ì •í•´ì„œ ê³¼ê²€ì¶œ(ê±°ì§“ì–‘ì„±)ì„ ì¤„ì„.\n",
    "filtered = cand[\n",
    "    (cand[\"delta\"] > gap_thr) |\n",
    "    (cand[\"log10_ratio\"] > logr_thr)\n",
    "]\n",
    "\n",
    "# ì„ê³„ê°’ í†µê³¼ ë‹¨ì–´ ìˆ˜ (í•„í„° ì „/í›„ ëª¨ë‘ í‘œê¸°)\n",
    "print(f\"ì„ê³„ê°’ í†µê³¼ ë‹¨ì–´ ìˆ˜: {len(filtered)} / {len(cand)} (ì›ë³¸ {len(out_sorted)})\")\n",
    "\n",
    "# ì €ì¥\n",
    "filtered.to_csv(out_filtered, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"âœ… ì™„ë£Œ:\")\n",
    "print(\" - ì „ì²´ í‘œ  :\", out_full)\n",
    "print(\" - ì„ê³„ê°’ í‘œ:\", out_filtered)  # ìµœì¢… Excess words ë¦¬ìŠ¤íŠ¸\n",
    "print(\" - ëŒ€ìƒ ë‹¨ì–´ ìˆ˜(ì›ë³¸):\", len(out_sorted))\n",
    "print(\" - ë¹ˆë„ í•„í„° í›„ ëŒ€ìƒ:\", len(cand))        \n",
    "print(\" - ì„ê³„ í†µê³¼ ìˆ˜     :\", len(filtered))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a09483",
   "metadata": {},
   "source": [
    "# 4) ê³¼ì‰ ì–´íœ˜ ë¶„ë¥˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta ë° ratio ê¸°ì¤€ ìƒìœ„ ê³¼ì‰ì–´íœ˜ 100 + 100 ë³‘í•© --> ìˆ˜ë™ ë¼ë²¨ë§ìš© íŒŒì¼ ìƒì„±\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path  \n",
    "\n",
    "base = Path(\"results_SS\")\n",
    "filtered = pd.read_csv(base / \"SS_excess_words_2024_filtered.csv\")\n",
    "\n",
    "# ì¸ë±ìŠ¤ ë³µì›/í‘œì¤€í™”: 'term' â†’ 'word' ë¡œ í†µì¼\n",
    "filtered = filtered.reset_index(drop=True)\n",
    "if \"word\" not in filtered.columns:\n",
    "    if \"term\" in filtered.columns:\n",
    "        filtered = filtered.rename(columns={\"term\": \"word\"})\n",
    "    elif \"index\" in filtered.columns:\n",
    "        filtered = filtered.rename(columns={\"index\": \"word\"})\n",
    "    elif \"Unnamed: 0\" in filtered.columns:\n",
    "        filtered = filtered.rename(columns={\"Unnamed: 0\": \"word\"})\n",
    "    else:\n",
    "        filtered = filtered.reset_index().rename(columns={\"index\": \"word\"})\n",
    "\n",
    "# ìˆ«ì ì»¬ëŸ¼ ë³´ì • (ì•ˆì „)\n",
    "for col in (\"delta\", \"ratio\"):\n",
    "    filtered[col] = pd.to_numeric(filtered[col], errors=\"coerce\")\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ê¸°ì¤€ ë­í‚¹ ê³„ì‚°(ì°¸ê³ ìš©)\n",
    "tmp = filtered.copy()\n",
    "tmp[\"delta_rank\"] = tmp[\"delta\"].rank(ascending=False, method=\"min\")\n",
    "tmp[\"ratio_rank\"] = tmp[\"ratio\"].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# Top100 ì¶”ì¶œ\n",
    "top_delta = filtered.nlargest(100, \"delta\")\n",
    "top_ratio = filtered.nlargest(100, \"ratio\")\n",
    "\n",
    "# í•©ì§‘í•© + ì¤‘ë³µ ì œê±°\n",
    "combined = pd.concat([top_delta, top_ratio], ignore_index=True).drop_duplicates(\"word\")\n",
    "\n",
    "# ë­í¬ ì—´ ë³‘í•©\n",
    "combined = combined.merge(tmp[[\"word\", \"delta_rank\", \"ratio_rank\"]], on=\"word\", how=\"left\")\n",
    "\n",
    "# ë¼ë²¨ ì»¬ëŸ¼ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if \"manual_label\" not in combined.columns:\n",
    "    combined[\"manual_label\"] = \"\"   # ì´í›„ ìˆ˜ë™ ë¼ë²¨ë§: style/content ë“±\n",
    "\n",
    "# === ì¶œë ¥ íŒŒì¼ëª…: ===\n",
    "out_csv   = base / \"SS_excess_words_top_combined_for_labeling.csv\"\n",
    "out_excel = base / \"SS_excess_words_top_combined_for_labeling.xlsx\"\n",
    "\n",
    "combined.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "combined.to_excel(out_excel, index=False)\n",
    "\n",
    "print(f\"âœ… ì´ {len(combined)}ê°œ ë‹¨ì–´ê°€ ì¶”ì¶œë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. â†’ {out_csv}\")\n",
    "print(f\"âœ… ì—‘ì…€ íŒŒì¼ë¡œë„ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. â†’ {out_excel}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316abf23",
   "metadata": {},
   "source": [
    "# 5-1) p vs ratio\n",
    "\n",
    "xì¶•ì€ 2024ë…„ ì‹¤ì œ ë¹ˆë„(p), yì¶•ì€ ì˜ˆìƒ ëŒ€ë¹„ ê³¼ì‰ ë¹„ìœ¨(r = p/q)ì„."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2A (SS): 2024 ë¹ˆë„(p) vs ê³¼ì‰ ë¹„ìœ¨(r=p/q), ìˆ˜ë™ ë¼ë²¨(manual_label)ë¡œ ìƒ‰ìƒ êµ¬ë¶„\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------\n",
    "# 1) ê²½ë¡œ & ë°ì´í„° ë¡œë“œ (SS)\n",
    "# ------------------------------\n",
    "base = Path(\"results_SS\")\n",
    "in_xlsx = base / \"SS_excess_words_top_labeled.xlsx\" #ë¼ë²¨ë§í•œ íŒŒì¼\n",
    "df = pd.read_excel(in_xlsx)\n",
    "\n",
    "# ------------------------------\n",
    "# 2) ì—´ ì´ë¦„ ê³ ì •\n",
    "# ------------------------------\n",
    "COL_P = \"p2024\"\n",
    "COL_RATIO = \"ratio\"\n",
    "COL_LABEL = \"manual_label\"\n",
    "COL_WORD = \"word\"\n",
    "\n",
    "# ------------------------------\n",
    "# 3) ì „ì²˜ë¦¬ \n",
    "# ------------------------------\n",
    "# p>0, ratio>1.5 êµ¬ê°„ë§Œ (ì› ì½”ë“œ ê¸°ì¤€)\n",
    "df = df[(df[COL_P] > 0) & (df[COL_RATIO] > 1.5)].copy()\n",
    "\n",
    "# ë¼ë²¨ ëˆ„ë½/ëŒ€ì†Œë¬¸ì/ê³µë°± ì •ë¦¬\n",
    "df[COL_LABEL] = (\n",
    "    df[COL_LABEL]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .replace({\"\": \"content\", \"nan\": \"content\"})\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 4) ì‹œê°í™”\n",
    "# ------------------------------\n",
    "palette = {\"style\": \"orange\", \"content\": \"blue\", \"ambiguous\": \"gray\"}\n",
    "present_labels = [lab for lab in [\"style\",\"content\",\"ambiguous\"] if lab in df[COL_LABEL].unique()]\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=df, x=COL_P, y=COL_RATIO,\n",
    "    hue=COL_LABEL, palette=palette, hue_order=present_labels or None,\n",
    "    s=50, edgecolor=\"k\", alpha=0.8\n",
    ")\n",
    "\n",
    "# ë¡œê·¸ì¶•\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "# yì¶• í•˜í•œ(=1.5) ê³ ì •, ìƒí•œì€ ë°ì´í„°ì— ë§ê²Œ ìë™\n",
    "plt.ylim(1.5, None)\n",
    "\n",
    "# ì„ê³„ì„ : ratio = p**4 (ê°€ì´ë“œë¼ì¸)\n",
    "p_min = max(df[COL_P].min(), 1e-8)\n",
    "p_max = df[COL_P].max()\n",
    "p_grid = np.logspace(np.log10(p_min), np.log10(p_max), 200)\n",
    "plt.plot(p_grid, p_grid**4, linestyle=\"dashed\", color=\"black\", linewidth=1)\n",
    "\n",
    "# ë¼ë²¨: ratio ìƒìœ„ 15ê°œ\n",
    "top_words = df.sort_values(by=COL_RATIO, ascending=False).head(15)\n",
    "for _, r in top_words.iterrows():\n",
    "    plt.text(r[COL_P], r[COL_RATIO], str(r[COL_WORD]), fontsize=9)\n",
    "\n",
    "plt.xlabel(\"p2024 (Frequency in 2024)\")\n",
    "plt.ylabel(\"Ratio (p / q)\")\n",
    "plt.title(\"SS Figure 2A: 2024 frequency vs ratio (ratio > 1.5)\")\n",
    "plt.legend(title=\"Label\", loc=\"upper left\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5) ì €ì¥\n",
    "# ------------------------------\n",
    "fig_dir = base / \"figures\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"SS_figure2A_p_vs_ratio.png\", dpi=300)\n",
    "plt.savefig(fig_dir / \"SS_figure2A_p_vs_ratio.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45aafe9",
   "metadata": {},
   "source": [
    "# 5-2) p vs delta\n",
    "xì¶•ì€ 2024ë…„ ë‹¨ì–´ ë¹ˆë„(p), yì¶•ì€ ê³¼ì‰ ì •ë„(Î”)ë¥¼ ë‚˜íƒ€ëƒ„.\n",
    "\n",
    "Î” > 0.005 ì´ìƒì¸ ë‹¨ì–´ë§Œ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f160217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2B (SS): 2024 ë¹ˆë„(p) vs delta(p - q)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 0) adjustText í´ë°±\n",
    "try:\n",
    "    from adjustText import adjust_text\n",
    "    HAS_ADJUST = True\n",
    "except Exception:\n",
    "    HAS_ADJUST = False\n",
    "\n",
    "# 1) ë°ì´í„° ë¡œë“œ (SS ë¼ë²¨ë§ íŒŒì¼)\n",
    "base = Path(\"results_SS\")\n",
    "in_xlsx = base / \"SS_excess_words_top_labeled.xlsx\"   # ë¼ë²¨ë§í•œ íŒŒì¼\n",
    "df = pd.read_excel(in_xlsx)\n",
    "\n",
    "# 2) ì»¬ëŸ¼ ì´ë¦„ ë§¤í•‘\n",
    "def pick(d, candidates, required=True):\n",
    "    for c in candidates:\n",
    "        if c in d.columns:\n",
    "            return c\n",
    "    if required:\n",
    "        raise KeyError(f\"Required column not found. Tried: {candidates}. Available: {list(d.columns)}\")\n",
    "    return None\n",
    "\n",
    "COL_P      = pick(df, [\"p2024\", \"p\", \"p_2024\"])\n",
    "COL_Q      = pick(df, [\"q2024\", \"q\", \"q_2024\"])\n",
    "COL_DELTA  = \"delta\"\n",
    "COL_WORD   = pick(df, [\"word\", \"term\"], required=False) or \"word\"\n",
    "COL_LABEL  = pick(df, [\"manual_label\", \"label\", \"type\"], required=False) or \"manual_label\"\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# 3) delta ì—†ìœ¼ë©´ ìƒì„±\n",
    "if COL_DELTA not in df.columns:\n",
    "    df[COL_DELTA] = df[COL_P] - df[COL_Q]\n",
    "\n",
    "# 4) ì „ì²˜ë¦¬: p>0, delta>0.005, ë¼ë²¨ ì •ê·œí™”\n",
    "df[COL_LABEL] = df.get(COL_LABEL, \"content\")\n",
    "df[COL_LABEL] = df[COL_LABEL].fillna(\"content\").astype(str).str.strip().str.lower()\n",
    "\n",
    "filtered_df = df[(df[COL_P] > 0) & (df[COL_DELTA] > 0.005)].copy()\n",
    "\n",
    "# 5) ìƒ‰ìƒ ë§¤í•‘\n",
    "color_map = {\"style\": \"orange\", \"content\": \"blue\", \"ambiguous\": \"gray\"}\n",
    "filtered_df[\"__color__\"] = filtered_df[COL_LABEL].map(color_map).fillna(\"gray\")\n",
    "\n",
    "# 6) ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(\n",
    "    filtered_df[COL_P],\n",
    "    filtered_df[COL_DELTA],\n",
    "    c=filtered_df[\"__color__\"],\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"k\",\n",
    "    linewidths=0.5,\n",
    ")\n",
    "\n",
    "plt.xlabel(f\"{COL_P} (Frequency in 2024)\")\n",
    "plt.ylabel(\"Delta (p - q)\")\n",
    "plt.title(\"SS Figure 2B: 2024 frequency vs delta (delta > 0.005)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "# 7) í…ìŠ¤íŠ¸ ë¼ë²¨ë§: delta ìƒìœ„ 30ê°œ\n",
    "top_labels = filtered_df.nlargest(30, COL_DELTA)\n",
    "texts = []\n",
    "for _, row in top_labels.iterrows():\n",
    "    texts.append(plt.text(row[COL_P], row[COL_DELTA], str(row.get(COL_WORD, \"\")), fontsize=9))\n",
    "\n",
    "if HAS_ADJUST and texts:\n",
    "    adjust_text(\n",
    "        texts,\n",
    "        arrowprops=dict(arrowstyle=\"-\", color=\"black\", lw=0.5),\n",
    "        only_move={\"points\": \"y\", \"text\": \"y\"},\n",
    "        expand_text=(1.05, 1.2),\n",
    "    )\n",
    "\n",
    "# 8) ë²”ë¡€\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"orange\", edgecolor=\"k\", label=\"Style\"),\n",
    "    Patch(facecolor=\"blue\", edgecolor=\"k\", label=\"Content\"),\n",
    "    Patch(facecolor=\"gray\", edgecolor=\"k\", label=\"Ambiguous\"),\n",
    "]\n",
    "plt.legend(handles=legend_elements, title=\"Label\", loc=\"upper left\")\n",
    "\n",
    "# 9) ì €ì¥\n",
    "fig_dir = base / \"figures\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"SS_figure2B_p_vs_delta.png\", dpi=300)\n",
    "plt.savefig(fig_dir / \"SS_figure2B_p_vs_delta.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee95648",
   "metadata": {},
   "source": [
    "# 5-3) 9ê°œ ë‹¨ì–´ì— ëŒ€í•œ ì—°ë„ë³„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b09bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS_figure1A_fixed_list.py\n",
    "# Figure 1A (Social Sciences): ê³ ì • 9ë‹¨ì–´ + ì—°ë„ë³„ p_tì™€ 2024 ì˜ˆìƒì„ (q_2024)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# 0) ê²½ë¡œ (SS)\n",
    "# -----------------------------\n",
    "labels_path      = Path(\"results_SS/SS_excess_words_top_labeled.xlsx\")\n",
    "word_counts_path = Path(\"results_SS/SS_word_year_matrix_counts.csv\")\n",
    "doc_counts_path  = Path(\"results_SS/SS_doc_counts.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) ë°ì´í„° ë¡œë“œ\n",
    "# -----------------------------\n",
    "labels = pd.read_excel(labels_path)\n",
    "labels.columns = [str(c).strip() for c in labels.columns]\n",
    "\n",
    "# ë‹¨ì–´-ì—°ë„ 'ë¬¸ì„œìˆ˜ ê¸°ì¤€' ì¹´ìš´íŠ¸ í–‰ë ¬\n",
    "if not word_counts_path.exists():\n",
    "    raise FileNotFoundError(f\"ë‹¨ì–´-ì—°ë„ ì¹´ìš´íŠ¸ í–‰ë ¬ CSV ì—†ìŒ: {word_counts_path}\")\n",
    "word_matrix = pd.read_csv(word_counts_path, index_col=0)\n",
    "\n",
    "# ì—°ë„ë³„ ë¬¸ì„œ ìˆ˜ (SSì—ì„œëŠ” n_docs ë‹¨ì¼ ì»¬ëŸ¼ + ì¸ë±ìŠ¤=ì—°ë„ í˜•íƒœ)\n",
    "if not doc_counts_path.exists():\n",
    "    raise FileNotFoundError(f\"ì—°ë„ë³„ ë¬¸ì„œ ìˆ˜ CSV ì—†ìŒ: {doc_counts_path}\")\n",
    "doc_counts = pd.read_csv(doc_counts_path, index_col=0).iloc[:, 0]  # Series (index=year, name=n_docs)\n",
    "doc_counts.index = doc_counts.index.map(lambda x: str(x).strip())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) ë¼ë²¨Â·ë‹¨ì–´ ì»¬ëŸ¼ ì •ê·œí™” + (ê³ ì • ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©)\n",
    "# -----------------------------\n",
    "def pick(df, candidates, required=True):\n",
    "    cols = [c for c in candidates if c in df.columns]\n",
    "    if cols: return cols[0]\n",
    "    if required:\n",
    "        raise KeyError(f\"Required column not found. Tried: {candidates}. Available: {list(df.columns)}\")\n",
    "    return None\n",
    "\n",
    "COL_WORD  = pick(labels, [\"word\", \"term\"])\n",
    "COL_LABEL = pick(labels, [\"manual_label\", \"label\", \"type\"])\n",
    "\n",
    "lab_df = labels[[COL_WORD, COL_LABEL]].copy()\n",
    "lab_df[COL_WORD]  = lab_df[COL_WORD].astype(str).str.lower().str.strip()\n",
    "lab_df[COL_LABEL] = lab_df[COL_LABEL].astype(str).str.lower().str.strip()\n",
    "\n",
    "# ğŸ”’ ê³ ì • 9ë‹¨ì–´ (ì¸ë¬¸í•™ì€ \"showcasing\", \"underscoring\", \"aligning\", \"additionally\", \"intricate\", \"notably\", \"delving\", \"reshaping\", \"gpt\")\n",
    "target_words_raw = [\n",
    "    \"additionally\", \"underscoring\", \"aligning\",\n",
    "    \"explores\", \"notably\" , \"comprehensive\",\n",
    "    \"ai\", \"delving\", \"these\"\n",
    "]\n",
    "\n",
    "# word_matrix ì¸ë±ìŠ¤ ì •ë¦¬ ë° êµì°¨ í™•ì¸\n",
    "word_matrix.index = word_matrix.index.astype(str).str.lower().str.strip()\n",
    "present = [w for w in target_words_raw if w in word_matrix.index]\n",
    "missing = [w for w in target_words_raw if w not in word_matrix.index]\n",
    "\n",
    "print(\"[ëŒ€ìƒ ë‹¨ì–´] (ì¡´ì¬):\", present)\n",
    "if missing:\n",
    "    print(\"[ê²½ê³ ] ë‹¨ì–´-ì—°ë„ í–‰ë ¬ì— ì—†ëŠ” ë‹¨ì–´:\", missing)\n",
    "\n",
    "target_words = present  # ì—†ëŠ” ë‹¨ì–´ ì œì™¸\n",
    "\n",
    "# ë¼ë²¨ ë§µ(ìƒ‰ìƒìš©)\n",
    "label_map = dict(zip(lab_df[COL_WORD], lab_df[COL_LABEL]))\n",
    "color_by_label = {\"style\": \"tab:orange\", \"content\": \"tab:blue\", \"ambiguous\": \"gray\"}\n",
    "\n",
    "# -----------------------------\n",
    "# 3) ì—°ë„ êµì§‘í•© ë° p ê³„ì‚°/ì™¸ì‚½\n",
    "# -----------------------------\n",
    "years_all = [str(y) for y in range(2004, 2025)]  # SS: 2004..2024\n",
    "word_matrix.columns = [str(c).strip() for c in word_matrix.columns]\n",
    "years = [y for y in years_all if (y in word_matrix.columns) and (y in doc_counts.index)]\n",
    "if not years:\n",
    "    raise ValueError(\"ê³µí†µ ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤. word_matrix ì»¬ëŸ¼/ë¬¸ì„œìˆ˜ ì¸ë±ìŠ¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "def compute_freq(word: str):\n",
    "    \"\"\"ì—°ë„ë³„ p=(a+1)/(b+1). a:í•´ë‹¹ ë‹¨ì–´ í¬í•¨ ë¬¸ì„œ ìˆ˜, b:í•´ë‹¹ ì—°ë„ ì „ì²´ ë¬¸ì„œ ìˆ˜\"\"\"\n",
    "    a = word_matrix.loc[word, years].astype(float) if word in word_matrix.index else pd.Series(0.0, index=years)\n",
    "    b = doc_counts.loc[years].astype(float)  # n_docs Series\n",
    "    p = (a + 1.0) / (b + 1.0)\n",
    "    return p.values.tolist()\n",
    "\n",
    "def extrapolate_q(p2021, p2022):\n",
    "    \"\"\"Kobakì‹: q_2024 = p2022 + 2 * max(p2022 - p2021, 0)\"\"\"\n",
    "    return p2022 + 2 * max(p2022 - p2021, 0)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) ì‹œê°í™”\n",
    "# -----------------------------\n",
    "n = len(target_words)\n",
    "rows, cols = 3, 3\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, word in enumerate(target_words):\n",
    "    ax = axes[i]\n",
    "    p_t = compute_freq(word)\n",
    "    lab = label_map.get(word, \"content\")\n",
    "    color = color_by_label.get(lab, \"gray\")\n",
    "\n",
    "    ax.plot(years, p_t, label=f\"{word}\", color=color, linewidth=2)\n",
    "\n",
    "    if (\"2021\" in years) and (\"2022\" in years) and (\"2024\" in years):\n",
    "        p2021 = p_t[years.index(\"2021\")]\n",
    "        p2022 = p_t[years.index(\"2022\")]\n",
    "        q_2024 = extrapolate_q(p2021, p2022)\n",
    "        ax.plot([\"2022\", \"2024\"], [p2022, q_2024],\n",
    "                color=\"black\", linestyle=\"--\", linewidth=1.2, label=\"Expected q (2024)\")\n",
    "\n",
    "    ax.set_title(f\"{word}  [{lab}]\", fontsize=11)\n",
    "    ax.tick_params(axis='x', labelrotation=45)\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(0, max(ymax, (max(p_t) if p_t else 0) * 1.15 + 1e-6))\n",
    "\n",
    "# ë‚¨ëŠ” ì„œë¸Œí”Œë¡¯ ì œê±°\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"SS Figure 1A: Word frequency over time with 2024 projection\",\n",
    "             fontsize=16, y=1.02)\n",
    "out_dir = Path(\"results_SS/figures\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(out_dir / \"SS_figure1A_word_timecourse_fixed.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(out_dir / \"SS_figure1A_word_timecourse_fixed.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
